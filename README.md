# Sims-normal
Sims-normal is an RGB-based unsupervised benchmark dataset for anomaly detection in industrial assembly line actions, specifically designed for research in anomaly detection and action recognition on production lines.
Existing systems for assembly line action recognition primarily focus on identifying actions within standard operating procedures (SOP). However, these systems have limitations when dealing with actions performed by operators outside of SOP in real production environments. In practical operations, operators may perform behaviors that are not covered by SOPs, posing challenges to current systems. To address this issue, we propose a new dataset aimed at encompassing a more diverse range of operational behaviors.

 The videos in this dataset have a resolution of 1280 x 720 pixels and a frame rate of 30 frames per second. The camera angle is positioned above and in front of the oper
ator, covering the upper part of the operator’s body and the operating area, as illustrated in Figure 4.1. The training set of this dataset consists of videos from 9 operators performing the same SOP, with each operator contributing 6 videos, totaling 54 videos and 158,737 frames in total. Each video is annotated with frame-level action labels to support the training of action recognition models. The training set includes 6 actions of the camera assembly line SOP: Waiting, Brush, Assemble, Screw in, Scan, and Sticker, detailed in Table 4.1. The test set comprises 21 videos totaling 72,314 frames, including 9,546 frames of anomalous actions deliberately introduced to evaluate the model’s performance in recognizing non-SOP behaviors. Anomalous behaviors are diverse and random, categorized into two types: simple anomalies and complex anomalies. Simple anomalies include behaviors clearly deviating from normal operations, such as sleeping or leaving the workstation, while complex anomalies appear to comply with SOP superficially but are unrelated, such as using a mobile phone or personal recording. The test set’s action labels include the 6 SOP actions and an additional ’Abnormal’ action label for anomalous behaviors. We provide frame-level abnormal annotations for anomaly detection tasks, where frames containing anomalous actions are labeled with a value of 1, and others with 0, indicating the presence of anomalous actions. Table 4.2 presents three examples of anomalous actions from the anomaly video dataset; however, note that the dataset covers additional anomalous operations beyond these three examples. Complete examples of anomalous actions are provided in the appendix
